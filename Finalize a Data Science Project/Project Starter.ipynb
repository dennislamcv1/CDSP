{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import software libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries.\n",
    "import sys                                                  # Read system parameters.\n",
    "import numpy as np                                          # Work with multi-dimensional arrays.\n",
    "import pandas as pd                                         # Manipulate and analyze data.\n",
    "import sqlite3                                              # Manage SQL databases.\n",
    "import matplotlib                                           # Create and format charts.\n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns                                       # Make charting easier.\n",
    "import yellowbrick                                          # Visualize elbow and silhouette plots.\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "import sklearn                                              # Train and evaluate machine learning models.\n",
    "from sklearn.model_selection import train_test_split, \\\n",
    "                                    learning_curve, \\\n",
    "                                    cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, \\\n",
    "                            confusion_matrix, \\\n",
    "                            classification_report, \\\n",
    "                            scorer, \\\n",
    "                            f1_score, \\\n",
    "                            recall_score, \\\n",
    "                            precision_score, \\\n",
    "                            roc_auc_score, \\\n",
    "                            plot_roc_curve, \\\n",
    "                            plot_precision_recall_curve, \\\n",
    "                            plot_confusion_matrix, \\\n",
    "                            r2_score, \\\n",
    "                            explained_variance_score, \\\n",
    "                            mean_absolute_error, \\\n",
    "                            mean_squared_error\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.dummy import DummyRegressor\n",
    "import scikitplot as skplt                                  # Generate plots from sklearn models.\n",
    "import xgboost                                              # Build gradient boosting models.\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "import pickle                                               # Save Python objects as binary files.\n",
    "from collections import Counter\n",
    "import warnings                                             # Suppress warnings.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ensure results are reproducible.\n",
    "np.random.seed(1)\n",
    "\n",
    "# Summarize software libraries used.\n",
    "print('Libraries used in this project:')\n",
    "print('- Python {}'.format(sys.version))\n",
    "print('- NumPy {}'.format(np.__version__))\n",
    "print('- pandas {}'.format(pd.__version__))\n",
    "print('- sqlite3 {}'.format(sqlite3.sqlite_version))\n",
    "print('- Matplotlib {}'.format(matplotlib.__version__))\n",
    "print('- Seaborn {}'.format(sns.__version__))\n",
    "print('- Yellowbrick {}'.format(yellowbrick.__version__))\n",
    "print('- scikit-learn {}'.format(sklearn.__version__))\n",
    "print('- scikit-plot {}'.format(skplt.__version__))\n",
    "print('- XGBoost {}'.format(xgboost.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the datasets at each stage of the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads the raw SQL dataset from the beginning of the Course 2 Project, before ETL is applied.\n",
    "\n",
    "conn = sqlite3.connect('data/prod_sample.db')\n",
    "\n",
    "retail_data_raw = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table'\", conn)\n",
    "\n",
    "retail_data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads the dataset from the beginning of the Course 3 Project, after ETL is applied but before the data is preprocessed.\n",
    "\n",
    "retail_data_etl = pd.read_pickle('data/online_history_cleaned.pickle')\n",
    "\n",
    "retail_data_etl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads the dataset that was created as a result of the Course 3 Project, after preprocessing is applied.\n",
    "\n",
    "retail_data_prep = pd.read_pickle('data/online_history_cleaned_final.pickle')\n",
    "\n",
    "retail_data_prep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads the dataset from the Course 4 Projects that was used to create the machine learning models.\n",
    "\n",
    "retail_data_ml = pd.read_pickle('data/customer_data.pickle')\n",
    "\n",
    "retail_data_ml.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the optimal models created from machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads the classification model that was deemed the best.\n",
    "\n",
    "classification_model = pickle.load(open('models/best_classification_model.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads the regression model that was deemed the best.\n",
    "\n",
    "regression_model = pickle.load(open('models/best_regression_model.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads the clustering model that was deemed optimal.\n",
    "\n",
    "clustering_model = pickle.load(open('models/optimal_clustering_model.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Generate a lift chart for `churned` and save it to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into target and features.\n",
    "\n",
    "target_data = retail_data_ml.churned\n",
    "features = retail_data_ml.drop(['churned'], axis = 1)\n",
    "\n",
    "# Split the dataset into separate training and testing sets.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, \n",
    "                                                    target_data,\n",
    "                                                    test_size = 0.3, \n",
    "                                                    random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions and prediction probabilities for the classifier.\n",
    "# These are necessary to create the lift chart.\n",
    "\n",
    "clf_pred = classification_model.predict(X_test)\n",
    "clf_probas = classification_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the lift chart for \"churned\".\n",
    "\n",
    "fig = plt.figure(figsize = (12, 8))\n",
    "ax = fig.subplots()\n",
    "skplt.metrics.plot_lift_curve(clf_pred, clf_probas, ax = ax)\n",
    "ax.set_title('Lift Chart for Customer Churn', weight = 'bold',\n",
    "              size = 18)\n",
    "ax.set_xlabel('Percentage of Customers', weight = 'bold',\n",
    "              size = 16, labelpad = 15)\n",
    "ax.set_ylabel('Lift', weight = 'bold', size = 16,\n",
    "              labelpad = 30, rotation = 'horizontal')\n",
    "ax.tick_params(labelsize = 14)\n",
    "ax.legend(loc = 'upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This saves the chart to a vector image (SVG) file format.\n",
    "# You can download the file from the same directory as this notebook and use it in your presentation.\n",
    "\n",
    "fig.savefig('lift_chart.svg', bbox_inches = 'tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
